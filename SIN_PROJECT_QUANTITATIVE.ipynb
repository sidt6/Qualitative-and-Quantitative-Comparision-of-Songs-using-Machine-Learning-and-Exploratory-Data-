{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH9xvn3T7Gn2"
      },
      "source": [
        "# **COMPARATIVE CLASSIFICATION OF QUALITATIVE AND QUANTITATIVE FEATURES OF SONGS AND VISUALIZATION OF FEATURES**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ge-PKUjZ-F6q"
      },
      "source": [
        "# **SUBMITTED BY:**\n",
        "# SIDDHARTH THAKUR - 20BCE1144"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whg4qhDD8i8A"
      },
      "source": [
        "# IMPORTING PACKAGES AND DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "T-1K3IuHiQG0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "data_frame = pd.read_csv(\"song.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbEFBKff0WVS",
        "outputId": "75e3090c-4ad9-45c1-9b05-b0c108902819"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['id', 'name', 'duration_ms', 'artists', 'release_date', 'danceability',\n",
              "       'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness',\n",
              "       'liveness', 'valence', 'tempo', 'time_signature', 'popularity', 'like'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_frame.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LunQGU0-1SHm"
      },
      "outputs": [],
      "source": [
        "Features = ['key', 'mode', 'speechiness', 'acousticness',\n",
        "       'liveness', 'valence', 'tempo', 'time_signature', 'popularity']\n",
        "Target = [\"like\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5c8JyfhSpL4v"
      },
      "outputs": [],
      "source": [
        "#Split dataset to Training Set & Test Set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = data_frame[Features]\n",
        "y = data_frame[Target]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "                        train_size = 0.8, \n",
        "                        test_size = 0.2, \n",
        "                        random_state= 10)\n",
        "\n",
        "\n",
        "\n",
        "x1 = X_train[Features]    #Features to train\n",
        "x2 = y_train[Target]      #Target Class to test\n",
        "y1 = X_test[Features]    #Features to test\n",
        "y2 = y_test[Target]      #Target Class to test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XCSzAWziHIcd"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "best_features= SelectKBest(score_func=chi2, k=3)\n",
        "fit= best_features.fit(X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "eCTq8c1oHuKk"
      },
      "outputs": [],
      "source": [
        "df_scores= pd.DataFrame(fit.scores_*100)\n",
        "df_columns= pd.DataFrame(X.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "ls-MIDiiHwzP",
        "outputId": "05cd4a1a-644e-4e62-d74b-ed6539ded239"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a02b2cf1-dac6-4666-a141-b63c1d8d4270\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Features</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>time_signature</td>\n",
              "      <td>0.371976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>speechiness</td>\n",
              "      <td>1.407587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>valence</td>\n",
              "      <td>2.916465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>acousticness</td>\n",
              "      <td>3.532265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>key</td>\n",
              "      <td>7.771609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>liveness</td>\n",
              "      <td>19.618293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mode</td>\n",
              "      <td>83.963936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>tempo</td>\n",
              "      <td>704.284628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>popularity</td>\n",
              "      <td>2365.200123</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a02b2cf1-dac6-4666-a141-b63c1d8d4270')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a02b2cf1-dac6-4666-a141-b63c1d8d4270 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a02b2cf1-dac6-4666-a141-b63c1d8d4270');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         Features        Score\n",
              "7  time_signature     0.371976\n",
              "2     speechiness     1.407587\n",
              "5         valence     2.916465\n",
              "3    acousticness     3.532265\n",
              "0             key     7.771609\n",
              "4        liveness    19.618293\n",
              "1            mode    83.963936\n",
              "6           tempo   704.284628\n",
              "8      popularity  2365.200123"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features_scores= pd.concat([df_columns, df_scores], axis=1)\n",
        "features_scores.columns= ['Features', 'Score']\n",
        "features_scores.sort_values(by = 'Score')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "eyKoZn83oAdn"
      },
      "outputs": [],
      "source": [
        "Features = ['key', 'mode', 'acousticness','liveness', 'tempo', 'popularity']\n",
        "Target = [\"like\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "o_e8j15Mp29s"
      },
      "outputs": [],
      "source": [
        "#Split dataset to Training Set & Test Set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = data_frame[Features]\n",
        "y = data_frame[Target]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "                        train_size = 0.8, \n",
        "                        test_size = 0.2, \n",
        "                        random_state= 10)\n",
        "\n",
        "\n",
        "\n",
        "x1 = X_train[Features]    #Features to train\n",
        "x2 = y_train[Target]      #Target Class to test\n",
        "y1 = X_test[Features]    #Features to test\n",
        "y2 = y_test[Target]      #Target Class to test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "XOC3D57S2OTQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import tree\n",
        "import graphviz \n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "EsvL5ryu2XJ5"
      },
      "outputs": [],
      "source": [
        "# create a DecisionTreeClassifier object\n",
        "clf = DecisionTreeClassifier(random_state=10)\n",
        "\n",
        "# fit the model to the data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# make predictions on the test set\n",
        "result = clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Rs1mk_3N1_1s"
      },
      "outputs": [],
      "source": [
        "# Model Evaluation\n",
        "from yellowbrick.classifier import ClassificationReport\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgkfgRC-2aGy",
        "outputId": "ebfbf56f-eca8-4ea2-f353-359c0b546665"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========== Decision Tree Results ==========\n",
            "Accuracy    : 0.9001994062126114\n",
            "Recall      : 0.9001994062126114\n",
            "Precision   : 0.5003985425705003\n",
            "F1 Score    : 0.5001994062126114\n"
          ]
        }
      ],
      "source": [
        "ac_sc = accuracy_score(y2, result)\n",
        "rc_sc = recall_score(y2, result, average=\"weighted\")\n",
        "pr_sc = precision_score(y2, result, average=\"weighted\")\n",
        "f1_sc = f1_score(y2, result, average='micro')\n",
        "confusion_m = confusion_matrix(y2, result)\n",
        "print(\"========== Decision Tree Results ==========\")\n",
        "print(\"Accuracy    : \", ac_sc)\n",
        "print(\"Recall      : \", rc_sc)\n",
        "print(\"Precision   : \", pr_sc)\n",
        "print(\"F1 Score    : \", f1_sc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIcw1NLEKN6J",
        "outputId": "d5ff3d14-57dd-402d-c0cc-ed46e82816aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|--- feature_3 <= 0.02\n",
            "|   |--- class: 1\n",
            "|--- feature_3 >  0.02\n",
            "|   |--- feature_2 <= 0.00\n",
            "|   |   |--- feature_5 <= 15.50\n",
            "|   |   |   |--- feature_4 <= 132.61\n",
            "|   |   |   |   |--- feature_2 <= 0.00\n",
            "|   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |--- feature_2 >  0.00\n",
            "|   |   |   |   |   |--- feature_4 <= 115.32\n",
            "|   |   |   |   |   |   |--- feature_5 <= 12.50\n",
            "|   |   |   |   |   |   |   |--- feature_3 <= 0.33\n",
            "|   |   |   |   |   |   |   |   |--- feature_4 <= 114.52\n",
            "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |   |--- feature_4 >  114.52\n",
            "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |--- feature_3 >  0.33\n",
            "|   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |--- feature_5 >  12.50\n",
            "|   |   |   |   |   |   |   |--- feature_4 <= 86.24\n",
            "|   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |--- feature_4 >  86.24\n",
            "|   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |--- feature_4 >  115.32\n",
            "|   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |--- feature_4 >  132.61\n",
            "|   |   |   |   |--- feature_0 <= 1.00\n",
            "|   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |--- feature_0 >  1.00\n",
            "|   |   |   |   |   |--- feature_2 <= 0.00\n",
            "|   |   |   |   |   |   |--- feature_0 <= 4.50\n",
            "|   |   |   |   |   |   |   |--- feature_2 <= 0.00\n",
            "|   |   |   |   |   |   |   |   |--- feature_3 <= 0.12\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_4 <= 144.76\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_4 >  144.76\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |   |--- feature_3 >  0.12\n",
            "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |--- feature_2 >  0.00\n",
            "|   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |--- feature_0 >  4.50\n",
            "|   |   |   |   |   |   |   |--- feature_3 <= 0.51\n",
            "|   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |--- feature_3 >  0.51\n",
            "|   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |--- feature_2 >  0.00\n",
            "|   |   |   |   |   |   |--- class: 0\n",
            "|   |   |--- feature_5 >  15.50\n",
            "|   |   |   |--- feature_4 <= 131.15\n",
            "|   |   |   |   |--- feature_2 <= 0.00\n",
            "|   |   |   |   |   |--- feature_1 <= 0.50\n",
            "|   |   |   |   |   |   |--- feature_3 <= 0.35\n",
            "|   |   |   |   |   |   |   |--- feature_2 <= 0.00\n",
            "|   |   |   |   |   |   |   |   |--- feature_5 <= 31.50\n",
            "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |   |--- feature_5 >  31.50\n",
            "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |--- feature_2 >  0.00\n",
            "|   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |--- feature_3 >  0.35\n",
            "|   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |--- feature_1 >  0.50\n",
            "|   |   |   |   |   |   |--- feature_5 <= 25.00\n",
            "|   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |--- feature_5 >  25.00\n",
            "|   |   |   |   |   |   |   |--- feature_4 <= 82.81\n",
            "|   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |--- feature_4 >  82.81\n",
            "|   |   |   |   |   |   |   |   |--- feature_4 <= 108.92\n",
            "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |   |--- feature_4 >  108.92\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_0 <= 4.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_0 >  4.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |--- feature_2 >  0.00\n",
            "|   |   |   |   |   |--- feature_4 <= 95.87\n",
            "|   |   |   |   |   |   |--- feature_4 <= 84.28\n",
            "|   |   |   |   |   |   |   |--- feature_5 <= 47.50\n",
            "|   |   |   |   |   |   |   |   |--- feature_3 <= 0.08\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_5 <= 25.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_5 >  25.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |   |--- feature_3 >  0.08\n",
            "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |--- feature_5 >  47.50\n",
            "|   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |--- feature_4 >  84.28\n",
            "|   |   |   |   |   |   |   |--- feature_4 <= 91.96\n",
            "|   |   |   |   |   |   |   |   |--- feature_4 <= 87.49\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_5 <= 30.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_5 >  30.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |   |--- feature_4 >  87.49\n",
            "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |--- feature_4 >  91.96\n",
            "|   |   |   |   |   |   |   |   |--- feature_2 <= 0.00\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_2 <= 0.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_4 <= 94.47\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 4\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_4 >  94.47\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_2 >  0.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |   |--- feature_2 >  0.00\n",
            "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |--- feature_4 >  95.87\n",
            "|   |   |   |   |   |   |--- feature_4 <= 119.69\n",
            "|   |   |   |   |   |   |   |--- feature_3 <= 0.41\n",
            "|   |   |   |   |   |   |   |   |--- feature_2 <= 0.00\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_2 <= 0.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_3 <= 0.07\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_3 >  0.07\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 4\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_2 >  0.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |   |--- feature_2 >  0.00\n",
            "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |--- feature_3 >  0.41\n",
            "|   |   |   |   |   |   |   |   |--- feature_0 <= 5.00\n",
            "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |   |--- feature_0 >  5.00\n",
            "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |--- feature_4 >  119.69\n",
            "|   |   |   |   |   |   |   |--- feature_3 <= 0.12\n",
            "|   |   |   |   |   |   |   |   |--- feature_2 <= 0.00\n",
            "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |   |--- feature_2 >  0.00\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_4 <= 121.14\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_4 >  121.14\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_0 <= 5.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_0 >  5.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |--- feature_3 >  0.12\n",
            "|   |   |   |   |   |   |   |   |--- feature_5 <= 26.50\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_3 <= 0.36\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_3 >  0.36\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |   |--- feature_5 >  26.50\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_3 <= 0.65\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_4 <= 120.77\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_4 >  120.77\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_3 >  0.65\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |--- feature_4 >  131.15\n",
            "|   |   |   |   |--- feature_5 <= 34.50\n",
            "|   |   |   |   |   |--- feature_2 <= 0.00\n",
            "|   |   |   |   |   |   |--- feature_1 <= 0.50\n",
            "|   |   |   |   |   |   |   |--- feature_3 <= 0.08\n",
            "|   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |--- feature_3 >  0.08\n",
            "|   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |--- feature_1 >  0.50\n",
            "|   |   |   |   |   |   |   |--- feature_4 <= 135.56\n",
            "|   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |--- feature_4 >  135.56\n",
            "|   |   |   |   |   |   |   |   |--- feature_3 <= 0.25\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_3 <= 0.17\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_4 <= 154.29\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_4 >  154.29\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_3 >  0.17\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |   |--- feature_3 >  0.25\n",
            "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |--- feature_2 >  0.00\n",
            "|   |   |   |   |   |   |--- feature_3 <= 0.06\n",
            "|   |   |   |   |   |   |   |--- feature_5 <= 28.50\n",
            "|   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |--- feature_5 >  28.50\n",
            "|   |   |   |   |   |   |   |   |--- feature_2 <= 0.00\n",
            "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |   |--- feature_2 >  0.00\n",
            "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |--- feature_3 >  0.06\n",
            "|   |   |   |   |   |   |   |--- feature_0 <= 1.50\n",
            "|   |   |   |   |   |   |   |   |--- feature_3 <= 0.19\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_3 <= 0.07\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_3 >  0.07\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |   |--- feature_3 >  0.19\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_2 <= 0.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_2 >  0.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |--- feature_0 >  1.50\n",
            "|   |   |   |   |   |   |   |   |--- feature_4 <= 175.13\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_5 <= 20.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_5 >  20.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_5 <= 27.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 4\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_5 >  27.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 4\n",
            "|   |   |   |   |   |   |   |   |--- feature_4 >  175.13\n",
            "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |--- feature_5 >  34.50\n",
            "|   |   |   |   |   |--- feature_2 <= 0.00\n",
            "|   |   |   |   |   |   |--- feature_0 <= 8.50\n",
            "|   |   |   |   |   |   |   |--- feature_5 <= 42.50\n",
            "|   |   |   |   |   |   |   |   |--- feature_4 <= 137.01\n",
            "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |   |--- feature_4 >  137.01\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_5 <= 36.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_5 >  36.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_3 <= 0.06\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_3 >  0.06\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 6\n",
            "|   |   |   |   |   |   |   |--- feature_5 >  42.50\n",
            "|   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |--- feature_0 >  8.50\n",
            "|   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |--- feature_2 >  0.00\n",
            "|   |   |   |   |   |   |--- feature_3 <= 0.09\n",
            "|   |   |   |   |   |   |   |--- feature_2 <= 0.00\n",
            "|   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |--- feature_2 >  0.00\n",
            "|   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |--- feature_3 >  0.09\n",
            "|   |   |   |   |   |   |   |--- feature_2 <= 0.00\n",
            "|   |   |   |   |   |   |   |   |--- feature_0 <= 3.00\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_4 <= 172.52\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_1 <= 0.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_1 >  0.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_4 >  172.52\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |   |--- feature_0 >  3.00\n",
            "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |--- feature_2 >  0.00\n",
            "|   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |--- feature_2 >  0.00\n",
            "|   |   |--- feature_4 <= 206.92\n",
            "|   |   |   |--- feature_4 <= 206.60\n",
            "|   |   |   |   |--- feature_4 <= 62.51\n",
            "|   |   |   |   |   |--- feature_5 <= 1.50\n",
            "|   |   |   |   |   |   |--- feature_3 <= 0.20\n",
            "|   |   |   |   |   |   |   |--- feature_3 <= 0.08\n",
            "|   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |--- feature_3 >  0.08\n",
            "|   |   |   |   |   |   |   |   |--- feature_2 <= 0.98\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_2 <= 0.97\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_3 <= 0.11\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_3 >  0.11\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_2 >  0.97\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |   |--- feature_2 >  0.98\n",
            "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |--- feature_3 >  0.20\n",
            "|   |   |   |   |   |   |   |--- feature_2 <= 0.81\n",
            "|   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |--- feature_2 >  0.81\n",
            "|   |   |   |   |   |   |   |   |--- feature_0 <= 6.00\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_2 <= 0.85\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_2 >  0.85\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |   |--- feature_0 >  6.00\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_1 <= 0.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_4 <= 45.72\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_4 >  45.72\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_1 >  0.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |--- feature_5 >  1.50\n",
            "|   |   |   |   |   |   |--- feature_3 <= 0.36\n",
            "|   |   |   |   |   |   |   |--- feature_3 <= 0.35\n",
            "|   |   |   |   |   |   |   |   |--- feature_4 <= 62.11\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_3 <= 0.11\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_0 <= 1.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 7\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_0 >  1.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 13\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_3 >  0.11\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_5 <= 45.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 22\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_5 >  45.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |   |--- feature_4 >  62.11\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_3 <= 0.11\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_2 <= 0.82\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_2 >  0.82\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_3 >  0.11\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_2 <= 0.99\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 5\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_2 >  0.99\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
            "|   |   |   |   |   |   |   |--- feature_3 >  0.35\n",
            "|   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |--- feature_3 >  0.36\n",
            "|   |   |   |   |   |   |   |--- feature_4 <= 62.14\n",
            "|   |   |   |   |   |   |   |   |--- feature_4 <= 61.02\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_2 <= 0.54\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_2 <= 0.49\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 7\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_2 >  0.49\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_2 >  0.54\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_2 <= 0.68\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 8\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_2 >  0.68\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 10\n",
            "|   |   |   |   |   |   |   |   |--- feature_4 >  61.02\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_2 <= 0.17\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_2 >  0.17\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_3 <= 0.85\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_3 >  0.85\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
            "|   |   |   |   |   |   |   |--- feature_4 >  62.14\n",
            "|   |   |   |   |   |   |   |   |--- feature_4 <= 62.40\n",
            "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |   |--- feature_4 >  62.40\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_3 <= 0.80\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_3 >  0.80\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |--- feature_4 >  62.51\n",
            "|   |   |   |   |   |--- feature_3 <= 0.27\n",
            "|   |   |   |   |   |   |--- feature_4 <= 177.16\n",
            "|   |   |   |   |   |   |   |--- feature_4 <= 176.67\n",
            "|   |   |   |   |   |   |   |   |--- feature_3 <= 0.09\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_2 <= 0.31\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_4 <= 128.21\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 38\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_4 >  128.21\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 36\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_2 >  0.31\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_3 <= 0.03\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 7\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_3 >  0.03\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 46\n",
            "|   |   |   |   |   |   |   |   |--- feature_3 >  0.09\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_2 <= 0.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_3 <= 0.25\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 21\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_3 >  0.25\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 6\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_2 >  0.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_3 <= 0.09\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 35\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_3 >  0.09\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 55\n",
            "|   |   |   |   |   |   |   |--- feature_4 >  176.67\n",
            "|   |   |   |   |   |   |   |   |--- feature_2 <= 0.79\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_3 <= 0.18\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_5 <= 40.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 8\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_5 >  40.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_3 >  0.18\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_2 <= 0.66\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_2 >  0.66\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |   |--- feature_2 >  0.79\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_2 <= 0.86\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_2 <= 0.81\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_2 >  0.81\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_2 >  0.86\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_4 <= 176.89\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_4 >  176.89\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 6\n",
            "|   |   |   |   |   |   |--- feature_4 >  177.16\n",
            "|   |   |   |   |   |   |   |--- feature_2 <= 0.16\n",
            "|   |   |   |   |   |   |   |   |--- feature_3 <= 0.13\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_5 <= 12.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_3 <= 0.12\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 10\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_3 >  0.12\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_5 >  12.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_5 <= 16.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 6\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_5 >  16.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 21\n",
            "|   |   |   |   |   |   |   |   |--- feature_3 >  0.13\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_5 <= 23.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_0 <= 6.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 9\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_0 >  6.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 7\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_5 >  23.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_2 <= 0.01\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 7\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_2 >  0.01\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 13\n",
            "|   |   |   |   |   |   |   |--- feature_2 >  0.16\n",
            "|   |   |   |   |   |   |   |   |--- feature_2 <= 0.31\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_1 <= 0.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_5 <= 5.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_5 >  5.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 15\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_1 >  0.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_0 <= 6.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 9\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_0 >  6.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 9\n",
            "|   |   |   |   |   |   |   |   |--- feature_2 >  0.31\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_2 <= 0.37\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_4 <= 178.45\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_4 >  178.45\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 12\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_2 >  0.37\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_4 <= 177.98\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 10\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_4 >  177.98\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 26\n",
            "|   |   |   |   |   |--- feature_3 >  0.27\n",
            "|   |   |   |   |   |   |--- feature_2 <= 0.00\n",
            "|   |   |   |   |   |   |   |--- feature_0 <= 8.50\n",
            "|   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |--- feature_0 >  8.50\n",
            "|   |   |   |   |   |   |   |   |--- feature_2 <= 0.00\n",
            "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |   |--- feature_2 >  0.00\n",
            "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |--- feature_2 >  0.00\n",
            "|   |   |   |   |   |   |   |--- feature_5 <= 32.50\n",
            "|   |   |   |   |   |   |   |   |--- feature_3 <= 0.35\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_2 <= 0.15\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_2 <= 0.03\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 20\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_2 >  0.03\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 21\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_2 >  0.15\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_5 <= 29.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 43\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_5 >  29.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 25\n",
            "|   |   |   |   |   |   |   |   |--- feature_3 >  0.35\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_3 <= 0.36\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_4 <= 82.79\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 5\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_4 >  82.79\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 17\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_3 >  0.36\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_2 <= 0.71\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 37\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_2 >  0.71\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 31\n",
            "|   |   |   |   |   |   |   |--- feature_5 >  32.50\n",
            "|   |   |   |   |   |   |   |   |--- feature_2 <= 0.00\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_2 <= 0.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_2 <= 0.00\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 14\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_2 >  0.00\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 7\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_2 >  0.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_3 <= 0.39\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 5\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_3 >  0.39\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 4\n",
            "|   |   |   |   |   |   |   |   |--- feature_2 >  0.00\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_5 <= 38.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_2 <= 0.98\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 36\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_2 >  0.98\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_5 >  38.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_4 <= 173.20\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 29\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_4 >  173.20\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 16\n",
            "|   |   |   |--- feature_4 >  206.60\n",
            "|   |   |   |   |--- feature_5 <= 40.00\n",
            "|   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |--- feature_5 >  40.00\n",
            "|   |   |   |   |   |--- class: 1\n",
            "|   |   |--- feature_4 >  206.92\n",
            "|   |   |   |--- feature_3 <= 0.13\n",
            "|   |   |   |   |--- feature_5 <= 41.50\n",
            "|   |   |   |   |   |--- feature_5 <= 1.50\n",
            "|   |   |   |   |   |   |--- feature_0 <= 6.00\n",
            "|   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |--- feature_0 >  6.00\n",
            "|   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |--- feature_5 >  1.50\n",
            "|   |   |   |   |   |   |--- feature_2 <= 0.81\n",
            "|   |   |   |   |   |   |   |--- feature_2 <= 0.44\n",
            "|   |   |   |   |   |   |   |   |--- feature_5 <= 34.50\n",
            "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |   |--- feature_5 >  34.50\n",
            "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |--- feature_2 >  0.44\n",
            "|   |   |   |   |   |   |   |   |--- feature_3 <= 0.12\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_4 <= 207.43\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_4 >  207.43\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_5 <= 24.00\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_5 >  24.00\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
            "|   |   |   |   |   |   |   |   |--- feature_3 >  0.12\n",
            "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |--- feature_2 >  0.81\n",
            "|   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |--- feature_5 >  41.50\n",
            "|   |   |   |   |   |--- class: 0\n",
            "|   |   |   |--- feature_3 >  0.13\n",
            "|   |   |   |   |--- feature_3 <= 0.15\n",
            "|   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |--- feature_3 >  0.15\n",
            "|   |   |   |   |   |--- feature_3 <= 0.56\n",
            "|   |   |   |   |   |   |--- feature_5 <= 2.50\n",
            "|   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |--- feature_5 >  2.50\n",
            "|   |   |   |   |   |   |   |--- feature_5 <= 27.00\n",
            "|   |   |   |   |   |   |   |   |--- feature_3 <= 0.19\n",
            "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |   |--- feature_3 >  0.19\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_3 <= 0.21\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_3 >  0.21\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_0 <= 1.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 4\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_0 >  1.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
            "|   |   |   |   |   |   |   |--- feature_5 >  27.00\n",
            "|   |   |   |   |   |   |   |   |--- feature_5 <= 32.50\n",
            "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |   |--- feature_5 >  32.50\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_5 <= 36.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_0 <= 6.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_0 >  6.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
            "|   |   |   |   |   |   |   |   |   |--- feature_5 >  36.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_5 <= 40.00\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |   |   |   |--- feature_5 >  40.00\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |--- feature_3 >  0.56\n",
            "|   |   |   |   |   |   |--- feature_2 <= 0.83\n",
            "|   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |--- feature_2 >  0.83\n",
            "|   |   |   |   |   |   |   |--- class: 1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn import tree\n",
        "textrepresentation = tree.export_text(clf)\n",
        "print(textrepresentation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "EOc-ZQWhPywU"
      },
      "outputs": [],
      "source": [
        "#feature scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X=StandardScaler()\n",
        "X_train=sc_X.fit_transform(X_train)\n",
        "X_test=sc_X.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAq8u-XlQmvY",
        "outputId": "e4d6e3af-8d0c-487f-f3ae-1bd0691c2fb6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "#### logistic regression\n",
        "\n",
        "#fitting LR to training set\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier =LogisticRegression()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "#Predict the test set results\n",
        "\n",
        "result=classifier.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkmM8thAQsO9",
        "outputId": "6ceb0a62-03fe-4f88-b980-db016e82a912"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========== Logistic Regression Results ==========\n",
            "Accuracy    : 0.9116320290689945\n",
            "Recall      : 0.9116320290689945\n",
            "Precision   : 0.9058700266893869\n",
            "F1 Score    : 0.9116320290689945\n"
          ]
        }
      ],
      "source": [
        "ac_sc = accuracy_score(y2, result)\n",
        "rc_sc = recall_score(y2, result, average=\"weighted\")\n",
        "pr_sc = precision_score(y2, result, average=\"weighted\")\n",
        "f1_sc = f1_score(y2, result, average='micro')\n",
        "confusion_m = confusion_matrix(y2, result)\n",
        "print(\"========== Logistic Regression Results ==========\")\n",
        "print(\"Accuracy    : \", ac_sc)\n",
        "print(\"Recall      : \", rc_sc)\n",
        "print(\"Precision   : \", pr_sc)\n",
        "print(\"F1 Score    : \", f1_sc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EPfJ7PYRV-T",
        "outputId": "c0f62349-c1d9-4849-9884-fa23938357c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-24-9a3d2a277d28>:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  rf_model.fit(X=x1,\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier,VotingClassifier\n",
        "rf_model = RandomForestClassifier(n_estimators=100, # Number of trees\n",
        "                                  min_samples_split = 30,\n",
        "                                  bootstrap = True, \n",
        "                                  max_depth = 50, \n",
        "                                  min_samples_leaf = 25)\n",
        "\n",
        "# Model Training\n",
        "rf_model.fit(X=x1,\n",
        "             y=x2)\n",
        "\n",
        "# Prediction\n",
        "result = rf_model.predict(y1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BGqHbGIU2EL",
        "outputId": "3ec0b258-7bfb-4bce-bcc1-2b8b089340b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========== Random Forest Results ==========\n",
            "Accuracy    : 0.9025479682722559\n",
            "Recall      : 0.9025479682722559\n",
            "Precision   : 0.9009508838040566\n",
            "F1 Score    : 0.9025479682722559\n"
          ]
        }
      ],
      "source": [
        "ac_sc = accuracy_score(y2, result)\n",
        "rc_sc = recall_score(y2, result, average=\"weighted\")\n",
        "pr_sc = precision_score(y2, result, average=\"weighted\")\n",
        "f1_sc = f1_score(y2, result, average='micro')\n",
        "confusion_m = confusion_matrix(y2, result)\n",
        "print(\"========== Random Forest Results ==========\")\n",
        "\n",
        "print(\"Accuracy    : \", ac_sc)\n",
        "print(\"Recall      : \", rc_sc)\n",
        "print(\"Precision   : \", pr_sc)\n",
        "print(\"F1 Score    : \", f1_sc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6UdDabBRb4W"
      },
      "outputs": [],
      "source": [
        "from sklearn import tree\n",
        "fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (4,4), dpi=800)\n",
        "tree.plot_tree(rf_model.estimators_[99],\n",
        "               filled = True);\n",
        "fig.savefig('rf_individualtree.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99tYt2xsQ6rW",
        "outputId": "55a1b3fb-12e7-4bb3-b3aa-4212903a7dd3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n"
          ]
        }
      ],
      "source": [
        "# K-Nearest Neighbors\n",
        "# Create Model with configuration \n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# Model Training\n",
        "knn_model.fit(X=x1,\n",
        "             y=x2)\n",
        "\n",
        "# Prediction\n",
        "result = knn_model.predict(y1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_kn4MmTRYz2",
        "outputId": "84b6283b-1377-4c8f-fd01-ee43a195bfea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========== KNN Results ==========\n",
            "Accuracy    : 0.9049851553152834\n",
            "Recall      : 0.9049851553152834\n",
            "Precision   : 0.9058700266893869\n",
            "F1 Score    : 0.9049851553152834\n"
          ]
        }
      ],
      "source": [
        "ac_sc = accuracy_score(y2, result)\n",
        "rc_sc = recall_score(y2, result, average=\"weighted\")\n",
        "pr_sc = precision_score(y2, result, average=\"weighted\")\n",
        "f1_sc = f1_score(y2, result, average='micro')\n",
        "confusion_m = confusion_matrix(y2, result)\n",
        "print(\"========== KNN Results ==========\")\n",
        "print(\"Accuracy    : \", ac_sc)\n",
        "print(\"Recall      : \", rc_sc)\n",
        "print(\"Precision   : \", pr_sc)\n",
        "print(\"F1 Score    : \", f1_sc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WARgCST9RABj",
        "outputId": "4c2aae24-c921-484d-f90a-e1b48ce1ebdd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "<ipython-input-29-9fc2561ac3d9>:11: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  error_rates.append(np.mean(new_predictions != result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "<ipython-input-29-9fc2561ac3d9>:11: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  error_rates.append(np.mean(new_predictions != result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "<ipython-input-29-9fc2561ac3d9>:11: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  error_rates.append(np.mean(new_predictions != result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "<ipython-input-29-9fc2561ac3d9>:11: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  error_rates.append(np.mean(new_predictions != result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "<ipython-input-29-9fc2561ac3d9>:11: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  error_rates.append(np.mean(new_predictions != result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "<ipython-input-29-9fc2561ac3d9>:11: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  error_rates.append(np.mean(new_predictions != result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "<ipython-input-29-9fc2561ac3d9>:11: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  error_rates.append(np.mean(new_predictions != result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "<ipython-input-29-9fc2561ac3d9>:11: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  error_rates.append(np.mean(new_predictions != result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "<ipython-input-29-9fc2561ac3d9>:11: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  error_rates.append(np.mean(new_predictions != result))\n"
          ]
        }
      ],
      "source": [
        "error_rates = []\n",
        "\n",
        "for i in np.arange(1, 10):\n",
        "\n",
        "    new_model = KNeighborsClassifier(n_neighbors = i)\n",
        "\n",
        "    new_model.fit(X_train, y_train)\n",
        "\n",
        "    new_predictions = new_model.predict(X_train)\n",
        "\n",
        "    error_rates.append(np.mean(new_predictions != result))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "aitCLiuBgvvR",
        "outputId": "3ebd52ef-5831-4092-abf2-a7b4a686fdfa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fc455706b20>]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(error_rates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmQNaKfbRDAd",
        "outputId": "379a3d21-0b6e-4ffa-91b7-9d69b714f1da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1096: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "# Neural Network\n",
        "# Create Model with configuration \n",
        "from sklearn.neural_network import MLPClassifier\n",
        "nn_model = MLPClassifier(solver='adam', \n",
        "                         alpha=1e-5,\n",
        "                         hidden_layer_sizes=(40,), \n",
        "                         random_state=1,\n",
        "                         max_iter=1000                         \n",
        "                        )\n",
        "\n",
        "# Model Training\n",
        "nn_model.fit(X=x1,\n",
        "             y=x2)\n",
        "\n",
        "# Prediction\n",
        "result = nn_model.predict(y1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoG0PK_zRGDV",
        "outputId": "27b5659b-7772-438b-e318-2d8ac9a2eb6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========== Neural Network Results ==========\n",
            "Accuracy    : 0.9018832808968848\n",
            "Recall      : 0.9018832808968848\n",
            "Precision   : 0.9069280518548183\n",
            "F1 Score    : 0.9018832808968848\n"
          ]
        }
      ],
      "source": [
        "# Model Evaluation\n",
        "ac_sc = accuracy_score(y2, result)\n",
        "rc_sc = recall_score(y2, result, average=\"weighted\")\n",
        "pr_sc = precision_score(y2, result, average=\"weighted\")\n",
        "f1_sc = f1_score(y2, result, average='micro')\n",
        "confusion_m = confusion_matrix(y2, result)\n",
        "\n",
        "print(\"========== Neural Network Results ==========\")\n",
        "print(\"Accuracy    : \", ac_sc)\n",
        "print(\"Recall      : \", rc_sc)\n",
        "print(\"Precision   : \", pr_sc)\n",
        "print(\"F1 Score    : \", f1_sc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbPD64mURJT7",
        "outputId": "47de2941-e244-4511-96d2-85f0aa5d05d6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
          ]
        }
      ],
      "source": [
        "# Ensemble Voting Model\n",
        "# Combine 3 Models to create an Ensemble Model\n",
        "# Create Model with configuration\n",
        "eclf1 = VotingClassifier(estimators=[('knn', knn_model), ('rf', rf_model), ('nn', nn_model)], \n",
        "                         weights=[1,1,1],\n",
        "                         flatten_transform=True)\n",
        "eclf1 = eclf1.fit(X=x1, y=x2)   \n",
        "\n",
        "# Prediction\n",
        "result = eclf1.predict(y1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1_f_ASEiFv9",
        "outputId": "3f582b78-6cfb-4dfa-b7a4-f4d760d9de46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========== Voting Model Results ==========\n",
            "Accuracy    : 0.9049851553152834\n",
            "Recall      : 0.9049851553152834\n",
            "Precision   : 0.9058700266893869\n",
            "F1 Score    : 0.9049851553152834\n"
          ]
        }
      ],
      "source": [
        "# Model Evaluation\n",
        "ac_sc = accuracy_score(y2, result)\n",
        "rc_sc = recall_score(y2, result, average=\"weighted\")\n",
        "pr_sc = precision_score(y2, result, average=\"weighted\")\n",
        "f1_sc = f1_score(y2, result, average='micro')\n",
        "confusion_m = confusion_matrix(y2, result)\n",
        "\n",
        "print(\"========== Voting Model Results ==========\")\n",
        "print(\"Accuracy    : \", ac_sc)\n",
        "print(\"Recall      : \", rc_sc)\n",
        "print(\"Precision   : \", pr_sc)\n",
        "print(\"F1 Score    : \", f1_sc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpgM68dWTpJQ",
        "outputId": "47510f9d-d40b-46e3-e343-85291b01a78a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "903/903 [==============================] - 4s 3ms/step - loss: 0.6999\n",
            "Epoch 2/100\n",
            "903/903 [==============================] - 2s 3ms/step - loss: 0.6936\n",
            "Epoch 3/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6933\n",
            "Epoch 4/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6932\n",
            "Epoch 5/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6931\n",
            "Epoch 6/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6931\n",
            "Epoch 7/100\n",
            "903/903 [==============================] - 3s 3ms/step - loss: 0.6931\n",
            "Epoch 8/100\n",
            "903/903 [==============================] - 2s 3ms/step - loss: 0.6931\n",
            "Epoch 9/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6930\n",
            "Epoch 10/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6930\n",
            "Epoch 11/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6930\n",
            "Epoch 12/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6930\n",
            "Epoch 13/100\n",
            "903/903 [==============================] - 2s 3ms/step - loss: 0.6930\n",
            "Epoch 14/100\n",
            "903/903 [==============================] - 3s 3ms/step - loss: 0.6930\n",
            "Epoch 15/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6930\n",
            "Epoch 16/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6930\n",
            "Epoch 17/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6930\n",
            "Epoch 18/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 19/100\n",
            "903/903 [==============================] - 2s 3ms/step - loss: 0.6930\n",
            "Epoch 20/100\n",
            "903/903 [==============================] - 3s 3ms/step - loss: 0.6930\n",
            "Epoch 21/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 22/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 23/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 24/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 25/100\n",
            "903/903 [==============================] - 3s 3ms/step - loss: 0.6929\n",
            "Epoch 26/100\n",
            "903/903 [==============================] - 2s 3ms/step - loss: 0.6929\n",
            "Epoch 27/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 28/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 29/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 30/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 31/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 32/100\n",
            "903/903 [==============================] - 3s 3ms/step - loss: 0.6929\n",
            "Epoch 33/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 34/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 35/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 36/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 37/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 38/100\n",
            "903/903 [==============================] - 3s 3ms/step - loss: 0.6929\n",
            "Epoch 39/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 40/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 41/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 42/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 43/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 44/100\n",
            "903/903 [==============================] - 2s 3ms/step - loss: 0.6929\n",
            "Epoch 45/100\n",
            "903/903 [==============================] - 3s 3ms/step - loss: 0.6929\n",
            "Epoch 46/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 47/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 48/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 49/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 50/100\n",
            "903/903 [==============================] - 3s 3ms/step - loss: 0.6929\n",
            "Epoch 51/100\n",
            "903/903 [==============================] - 2s 3ms/step - loss: 0.6929\n",
            "Epoch 52/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 53/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 54/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 55/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 56/100\n",
            "903/903 [==============================] - 3s 3ms/step - loss: 0.6929\n",
            "Epoch 57/100\n",
            "903/903 [==============================] - 3s 3ms/step - loss: 0.6929\n",
            "Epoch 58/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 59/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 60/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 61/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 62/100\n",
            "903/903 [==============================] - 3s 3ms/step - loss: 0.6928\n",
            "Epoch 63/100\n",
            "903/903 [==============================] - 3s 3ms/step - loss: 0.6929\n",
            "Epoch 64/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 65/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 66/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 67/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 68/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 69/100\n",
            "903/903 [==============================] - 3s 3ms/step - loss: 0.6929\n",
            "Epoch 70/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 71/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 72/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 73/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 74/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6928\n",
            "Epoch 75/100\n",
            "903/903 [==============================] - 3s 3ms/step - loss: 0.6929\n",
            "Epoch 76/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 77/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6928\n",
            "Epoch 78/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 79/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6928\n",
            "Epoch 80/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 81/100\n",
            "903/903 [==============================] - 3s 4ms/step - loss: 0.6929\n",
            "Epoch 82/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6928\n",
            "Epoch 83/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6928\n",
            "Epoch 84/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6929\n",
            "Epoch 85/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6928\n",
            "Epoch 86/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6928\n",
            "Epoch 87/100\n",
            "903/903 [==============================] - 3s 3ms/step - loss: 0.6929\n",
            "Epoch 88/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6928\n",
            "Epoch 89/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6928\n",
            "Epoch 90/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6928\n",
            "Epoch 91/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6928\n",
            "Epoch 92/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6928\n",
            "Epoch 93/100\n",
            "903/903 [==============================] - 3s 3ms/step - loss: 0.6928\n",
            "Epoch 94/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6928\n",
            "Epoch 95/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6928\n",
            "Epoch 96/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6928\n",
            "Epoch 97/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6928\n",
            "Epoch 98/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6928\n",
            "Epoch 99/100\n",
            "903/903 [==============================] - 3s 3ms/step - loss: 0.6928\n",
            "Epoch 100/100\n",
            "903/903 [==============================] - 2s 2ms/step - loss: 0.6928\n",
            "706/706 [==============================] - 2s 2ms/step - loss: 0.6930\n",
            "Accuracy: 69.30\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "# create the ANN model\n",
        "model = Sequential()\n",
        "model.add(Dense(8, input_dim=6, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "\n",
        "# train the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=100)\n",
        "\n",
        "# evaluate the model on the testing set\n",
        "accuracy = model.evaluate(X_test, y_test)\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
